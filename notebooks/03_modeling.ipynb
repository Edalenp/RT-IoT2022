{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected Algorithms\n",
    "\n",
    "For this IoT intrusion detection problem, we have selected a diverse set of classic supervised learning algorithms:\n",
    "\n",
    "1.  **Logistic Regression**\n",
    "2.  **Decision Tree**\n",
    "3.  **Random Forest**\n",
    "4.  **k-Nearest Neighbors (KNN)**\n",
    "5.  **Support Vector Machine (SVM)**\n",
    "6.  **Naïve Bayes (GaussianNB)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load processed data\n",
    "train_df = pd.read_csv('../data/processed/train_processed.csv')\n",
    "\n",
    "# Separate features and target\n",
    "target_col = 'Attack_type'\n",
    "X_train = train_df.drop(target_col, axis=1)\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'NaiveBayes': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification\n",
    "\n",
    "The selection of these models is based on the following criteria:\n",
    "\n",
    "*   **Interpretability**: **Decision Trees** and **Logistic Regression** offer a clear view of how features influence classification, which is crucial for understanding the nature of attacks.\n",
    "*   **Efficiency**: **Naïve Bayes** and **KNN** are computationally lightweight (in training or prediction), making them interesting candidates for resource-constrained IoT devices.\n",
    "*   **Expected Performance**: **Random Forest** and **SVM** are known for their robustness and ability to handle complex, high-dimensional data, typical characteristics of network traffic in attack scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "The training process includes:\n",
    "\n",
    "*   **Hyperparameters**: Specific search grids are defined for each algorithm (e.g., `n_estimators` for RF, `C` for SVM, `n_neighbors` for KNN).\n",
    "*   **Cross-Validation**: We use **GridSearchCV** with 3-fold cross-validation (cv=3) to ensure results are generalizable and do not depend on a specific data split.\n",
    "*   **Optimization**: GridSearch exhaustively explores hyperparameter combinations to find the optimal configuration (based on 'accuracy')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best LogisticRegression Score: 0.9929\n",
      "Best Parameters: {'C': 10}\n",
      "Model saved to ../results/models/LogisticRegression_best.pkl\n",
      "------------------------------\n",
      "Training DecisionTree...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best DecisionTree Score: 0.9985\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': None}\n",
      "Model saved to ../results/models/DecisionTree_best.pkl\n",
      "------------------------------\n",
      "Training RandomForest...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best RandomForest Score: 0.9987\n",
      "Best Parameters: {'max_depth': None, 'n_estimators': 100}\n",
      "Model saved to ../results/models/RandomForest_best.pkl\n",
      "------------------------------\n",
      "Training KNN...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best KNN Score: 0.9970\n",
      "Best Parameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Model saved to ../results/models/KNN_best.pkl\n",
      "------------------------------\n",
      "Training SVM...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best SVM Score: 0.9933\n",
      "Best Parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "Model saved to ../results/models/SVM_best.pkl\n",
      "------------------------------\n",
      "Training NaiveBayes...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best NaiveBayes Score: 0.9530\n",
      "Best Parameters: {'var_smoothing': 1e-08}\n",
      "Model saved to ../results/models/NaiveBayes_best.pkl\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    'LogisticRegression': {'C': [0.1, 1, 10]},\n",
    "    'DecisionTree': {'max_depth': [None, 10, 20], 'criterion': ['gini', 'entropy']},\n",
    "    'RandomForest': {'n_estimators': [50, 100], 'max_depth': [None, 10]},\n",
    "    'KNN': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']},\n",
    "    'SVM': {'C': [0.1, 1], 'kernel': ['rbf', 'linear']},\n",
    "    'NaiveBayes': {'var_smoothing': [1e-9, 1e-8]}\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "os.makedirs('../results/models', exist_ok=True)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    # Using a smaller subset for SVM/KNN to speed up demonstration if needed, \n",
    "    # but here we use full X_train. Note: SVM can be slow on large datasets.\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    print(f\"Best {name} Score: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(grid_search.best_estimator_, f'../results/models/{name}_best.pkl')\n",
    "    print(f\"Model saved to ../results/models/{name}_best.pkl\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges Encountered\n",
    "\n",
    "During the modeling phase, it is common to face the following challenges:\n",
    "\n",
    "*   **Class Imbalance**: As seen in the exploratory analysis, some attack classes are very minority. This can bias models (especially Accuracy) towards the majority class. Mitigation techniques like resampling (SMOTE) or class weights (`class_weight='balanced'`) could be used.\n",
    "*   **Training Time**: Algorithms like SVM and KNN can be computationally expensive with large data volumes (90k+ rows), slowing down hyperparameter search.\n",
    "*   **Overfitting**: Complex models like Random Forest or deep trees can memorize training data noise. Cross-validation and limiting depth (`max_depth`) help control this.\n",
    "*   **Preprocessing**: Scale-sensitive algorithms (SVM, KNN, Logistic Regression) require data to be normalized (StandardScaler), a step we performed in the previous stage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
